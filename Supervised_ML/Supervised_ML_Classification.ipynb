{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***IMPORTING LIBRARIES AND MODULES***"
      ],
      "metadata": {
        "id": "ngdGtjP5RPzz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhYKzA3rQyJ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import set_config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n"
      ],
      "metadata": {
        "id": "ePiktVF1lo9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***GET DATAS***"
      ],
      "metadata": {
        "id": "bW7l5yV1R6YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/file/d/1NFHZhCOxgW1bu5q32OqVIVBDtSo2Alkh/view?usp=sharing\"\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "data = df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "fotUlRGNU_wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***SPLIT DATAS***"
      ],
      "metadata": {
        "id": "cWa-7CEpR_C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X and y creation\n",
        "X = data.copy()\n",
        "X.pop('Id')\n",
        "y = X.pop(\"Expensive\")\n",
        "# data splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "I6IICHIdR126"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***PREPROCESSOR***"
      ],
      "metadata": {
        "id": "BRmKVtjcSJU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. defining categorical & ordinal columns\n",
        "X_cat = X.select_dtypes(exclude=\"number\").copy()\n",
        "X_num = X.select_dtypes(include=\"number\").copy()\n",
        "\n",
        "# 2. numerical pipeline\n",
        "numeric_pipe = make_pipeline(SimpleImputer())\n",
        "\n",
        "# 3. categorical pipeline\n",
        "    # # 3.1 defining ordinal & onehot columns\n",
        "\n",
        "ordinal_col_names = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
        "       'BsmtFinType1', 'KitchenQual', 'FireplaceQu', 'LotShape',\n",
        "       'BsmtFinType2', 'HeatingQC', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
        "       'PoolQC', 'Fence']\n",
        "\n",
        "ordinal_cols = X_cat.columns.get_indexer(ordinal_col_names)\n",
        "ohe_cols = X_cat.columns.get_indexer(list(set(X_cat) - set(ordinal_col_names)))\n",
        "\n",
        "X_cat_ordinal = X_cat.columns[ordinal_cols]\n",
        "X_cat_ohe = X_cat.columns[ohe_cols]\n",
        "\n",
        "    ## 3.2 explicitly determine categories for ordinal encoding including \"N_A\"\n",
        "ExterQual_cats = [\"N_A\",\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "ExterCond_cats = [\"N_A\",\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "BsmtQual_cats = [\"N_A\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "BsmtCond_cats = [\"N_A\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "BsmtExposure_cats = [\"N_A\", \"No\", \"Mn\", \"Av\", \"Gd\"]\n",
        "BsmtFinType1_cats = [\"N_A\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"]\n",
        "KitchenQual_cats = [\"N_A\",\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "FireplaceQu_cats = [\"N_A\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "LotShape_cats = [\"N_A\",'Reg', 'IR1', 'IR2', 'IR3']\n",
        "BsmtFinType2_cats = ['N_A','Unf','LwQ','Rec','BLQ','ALQ','GLQ']\n",
        "HeatingQC_cats = [\"N_A\",\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "GarageFinish_cats = ['N_A','Unf','RFn','Fin']\n",
        "GarageQual_cats = [\"N_A\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "GarageCond_cats = [\"N_A\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "PoolQC_cats = [\"N_A\",\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
        "Fence_cats = [\"N_A\",'NA','MnWw','GdWo','MnPrv','GdPrv']\n",
        "\n",
        "cats_ord = [ExterQual_cats, ExterCond_cats, BsmtQual_cats, BsmtCond_cats, \n",
        "            BsmtExposure_cats, BsmtFinType1_cats, KitchenQual_cats, FireplaceQu_cats, \n",
        "            LotShape_cats,BsmtFinType2_cats,HeatingQC_cats,GarageFinish_cats,GarageQual_cats,\n",
        "            GarageCond_cats,PoolQC_cats,Fence_cats]\n",
        "\n",
        "        ### 3.2.2. defining the categorical encoder: a ColumnTransformer with 2 branches: ordinal & onehot\n",
        "categorical_encoder = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat_ordinal\", OrdinalEncoder(categories=cats_ord), ordinal_cols),\n",
        "        (\"cat_onehot\", OneHotEncoder(handle_unknown=\"ignore\"), ohe_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "    ## 3.3. categorical pipeline = \"N_A\" imputer + categorical encoder\n",
        "categorical_pipe = make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=\"N_A\"),\n",
        "                                 categorical_encoder\n",
        "                                )\n",
        "\n",
        "# 4. full preprocessing: a ColumnTransformer with 2 branches: numeric & categorical\n",
        "full_preprocessing = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num_pipe\", numeric_pipe, X_num.columns),\n",
        "        (\"cat_pipe\", categorical_pipe, X_cat.columns),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "PThBYb1FSM84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***MODELLING***"
      ],
      "metadata": {
        "id": "SPfEcxc4T2YA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *DecisionTreeClassifier* "
      ],
      "metadata": {
        "id": "PTAj0m0YT5zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "full_pipeline = make_pipeline(full_preprocessing, \n",
        "                              scaler,\n",
        "                              DecisionTreeClassifier())\n",
        "\n",
        "param_grid = {\n",
        "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"mean\", \"median\",\"contant\"],\n",
        "    \"standardscaler__with_mean\": [True, False],\n",
        "    \"standardscaler__with_std\": [True, False],\n",
        "    \"decisiontreeclassifier__max_depth\": range(2, 15, 2),\n",
        "    \"decisiontreeclassifier__min_samples_leaf\": range(10, 100, 10),\n",
        "    \"decisiontreeclassifier__criterion\": [\"gini\", \"entropy\"]\n",
        "    \n",
        "\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(full_pipeline,\n",
        "                      param_grid,\n",
        "                      cv=5,\n",
        "                      scoring='accuracy',\n",
        "                      verbose=1, n_iter=100)\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# create a dictionary to keep track of the scores of different models \n",
        "scores = {\"dtree\" : search.best_score_}\n"
      ],
      "metadata": {
        "id": "8KvhxalWT1mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_pred_test = search.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_dt = accuracy_score(y_true = y_test,\n",
        "               y_pred = dt_pred_test\n",
        "              )\n",
        "\n",
        "scores[\"accuracy_dt\"] = accuracy_dt"
      ],
      "metadata": {
        "id": "cXChEqOx-zOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *KNN*"
      ],
      "metadata": {
        "id": "2vV7CgvS92lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_full_pipeline = make_pipeline(full_preprocessing,\n",
        "                                  scaler,\n",
        "                                  KNeighborsClassifier()\n",
        "                                 )\n",
        "\n",
        "param_grid = {\n",
        "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"mean\", \"median\",\"contant\"],\n",
        "    \"standardscaler__with_mean\": [True, False],\n",
        "    \"standardscaler__with_std\": [True, False],\n",
        "    \"kneighborsclassifier__n_neighbors\": range(2, 50),\n",
        "    \"kneighborsclassifier__weights\": [\"uniform\", \"distance\"]\n",
        "}\n",
        "\n",
        "knn_search = RandomizedSearchCV(knn_full_pipeline,\n",
        "                      param_grid,\n",
        "                      cv=5,\n",
        "                      scoring='accuracy',\n",
        "                      verbose=1, n_iter=100)\n",
        "\n",
        "knn_search.fit(X_train, y_train)\n",
        "\n",
        "scores[\"knn\"] = knn_search.best_score_"
      ],
      "metadata": {
        "id": "wTco5mVKWBoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_pred_test = knn_search.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_knn = accuracy_score(y_true = y_test,\n",
        "               y_pred = knn_pred_test\n",
        "              )\n",
        "\n",
        "scores[\"accuracy_knn\"] = accuracy_knn"
      ],
      "metadata": {
        "id": "HPxTALk2_l23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Logistic Regression*"
      ],
      "metadata": {
        "id": "4SmOx31-qdZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "LR_full_pipeline = make_pipeline(full_preprocessing,scaler, LogisticRegression())\n",
        "\n",
        "param_grid = {\n",
        "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"mean\", \"median\",\"contant\"],\n",
        "    \"standardscaler__with_mean\": [True, False],\n",
        "    \"standardscaler__with_std\": [True, False],\n",
        "    \"logisticregression__max_iter\": range(1,100,10),\n",
        "}\n",
        "\n",
        "LR_search = RandomizedSearchCV(LR_full_pipeline,\n",
        "                         param_grid,\n",
        "                         cv=13,\n",
        "                         scoring='accuracy',\n",
        "                         verbose=1, n_iter=100)\n",
        "\n",
        "LR_search.fit(X_train, y_train)\n",
        "\n",
        "scores[\"LRegression\"] = LR_search.best_score_"
      ],
      "metadata": {
        "id": "JZpjGS8dP-F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_pred_test = LR_search.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_LR = accuracy_score(y_true = y_test,\n",
        "               y_pred = LR_pred_test\n",
        "              )\n",
        "\n",
        "scores[\"accuracy_LR\"] = accuracy_LR"
      ],
      "metadata": {
        "id": "xUgPE-QIAB_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *SVC*"
      ],
      "metadata": {
        "id": "NaxZzzaQ_-f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVC_full_pipeline = make_pipeline(full_preprocessing,scaler, SVC())\n",
        "\n",
        "param_grid = {\n",
        "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"mean\", \"median\",\"contant\"],\n",
        "    \"standardscaler__with_mean\": [True, False],\n",
        "    \"standardscaler__with_std\": [True, False],\n",
        "    \"svc__gamma\":['scale', 'auto'],\n",
        "    \"svc__max_iter\":range(1,200,10),\n",
        "\n",
        "}\n",
        "\n",
        "SVC_search = RandomizedSearchCV(SVC_full_pipeline,\n",
        "                          param_grid, \n",
        "                          cv=10, \n",
        "                          scoring=\"accuracy\",\n",
        "                          verbose=1, n_iter=100)\n",
        "\n",
        "SVC_search.fit(X_train, y_train)\n",
        "scores[\"SVC\"] = SVC_search.best_score_"
      ],
      "metadata": {
        "id": "W_es5sxWpw6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVC_pred_test = SVC_search.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_SVC = accuracy_score(y_true = y_test,\n",
        "               y_pred = SVC_pred_test\n",
        "              )\n",
        "\n",
        "scores[\"accuracy_SVC\"] = accuracy_SVC"
      ],
      "metadata": {
        "id": "76LNCVwEALnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Random Forest*"
      ],
      "metadata": {
        "id": "_3P1Ey6o958O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RandomForest_pipeline = make_pipeline(full_preprocessing, scaler, RandomForestClassifier())\n",
        "\n",
        "param_grid = {\n",
        "    \"columntransformer__num_pipe__simpleimputer__strategy\":[\"mean\", \"median\",\"contant\"],\n",
        "    \"standardscaler__with_mean\": [True, False],\n",
        "    \"standardscaler__with_std\": [True, False],\n",
        "    \"randomforestclassifier__n_estimators\": range(10, 100, 20),\n",
        "    \"randomforestclassifier__max_depth\": range(2, 15, 2),\n",
        "    \"randomforestclassifier__min_samples_leaf\": range(10, 300, 50),\n",
        "    \"randomforestclassifier__criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "RandomForest_search = RandomizedSearchCV(RandomForest_pipeline,\n",
        "                                   param_grid,\n",
        "                                   cv=5,\n",
        "                                   scoring=\"accuracy\",\n",
        "                                   verbose=1, n_iter=100)\n",
        "\n",
        "RandomForest_search.fit(X_train, y_train)\n",
        "\n",
        "scores['RandomForest'] = RandomForest_search.best_score_"
      ],
      "metadata": {
        "id": "9sTE7pJpuVsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF_pred_test = RandomForest_search.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_RF = accuracy_score(y_true = y_test,\n",
        "               y_pred = RF_pred_test\n",
        "              )\n",
        "\n",
        "scores[\"accuracy_RF\"] = accuracy_RF"
      ],
      "metadata": {
        "id": "3KL-jfSlAVNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "Pty1HhYWpr0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \" https://drive.google.com/file/d/15PfmTxmavQCT-f7iY9tgwWxm9t4GRees/view?usp=sharing\"\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "Competition_DF = competition_df = pd.read_csv(path)\n",
        "\n",
        "Compet_DF = Competition_DF.copy()\n",
        "Compet_DF.pop('Id')\n",
        "\n",
        "Alex_Compet_Submission = pd.DataFrame(Competition_DF[\"Id\"])\n",
        "\n",
        "LR_pred_sub = RandomForest_search.predict(Compet_DF)\n",
        "\n",
        "Alex_Compet_Submission[\"Expensive\"] = LR_pred_sub\n",
        "Alex_Compet_Submission.head()\n",
        "Alex_Compet_Submission.to_csv('Alex_Compet.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download(\"Alex_Compet.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zX9bX2CqH6RS",
        "outputId": "c02d56cc-0eda-43cb-f76a-d1ec653c4e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8704e526-6477-48ed-8c81-94c896216db2\", \"Alex_RandomForest.csv\", 10226)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}